{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Prices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz-yCvQIfRDf"
      },
      "source": [
        "# Stock Market Prediction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geFGFymfCM--"
      },
      "source": [
        "\n",
        "\n",
        "1.   Amazon - AMZN\n",
        "2.   Apple - AAPL\n",
        "3.   Microsoft - MSFT\n",
        "4. Google - GOOGL\n",
        "5. Tesla - TSLA\n",
        "6. Oracle - ORCL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "viG2N_9pfRDj"
      },
      "source": [
        "# Dataset download\n",
        "import pandas_datareader as pr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "step = 70 # time step\n",
        "company = 'ORCL'\n",
        "price_type = 'close'\n",
        "\n",
        "data = pr.get_data_tiingo(company, api_key=\"0f6351ae343427e511f4d085681db7e303ffb969\")\n",
        "data.to_csv(company+'.csv')\n",
        "\n",
        "data = pd.read_csv(company+'.csv')\n",
        "\n",
        "\n",
        "def create_dataset(dataset, time_step=1):\n",
        "  dataX, dataY = [], []\n",
        "  for i in range(len(dataset)-time_step-1):\n",
        "    a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + time_step, 0])\n",
        "  return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# Baseline calculation\n",
        "\n",
        "Base_errors = []\n",
        "\n",
        "for price_type in ['open','close','high','low']:\n",
        "\n",
        "  Price = data[price_type]\n",
        "  Means = list()\n",
        "\n",
        "  for i in range(len(Price) - step):\n",
        "    Means.append(sum(Price[i:i+step])/step)  \n",
        "\n",
        "  Error = math.sqrt(mean_squared_error(Price[step:],Means))\n",
        "  Base_errors.append(Error)   \n",
        "  print(\"Base case error for\",price_type,\"=\",Error)    \n",
        "  #plt.plot(Price)\n",
        "\n",
        "\n",
        "  # MinMax Scalimg\n",
        "  import numpy as np\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "  mms = MinMaxScaler(feature_range=(0,1))\n",
        "  Price = mms.fit_transform(np.array(Price).reshape(-1,1))\n",
        "\n",
        "  # Dataset split into train and test sets\n",
        "\n",
        "  train_size = int(len(Price)*0.80)\n",
        "  test_size = len(Price)-train_size\n",
        "  train_data,test_data = Price[0:train_size,:],Price[train_size:len(Price),:1]\n",
        "  train_size, test_size\n",
        "\n",
        "  # Converting data to timeseries input\n",
        "\n",
        "  time_step = step\n",
        "  trainX, trainY = create_dataset(train_data, time_step)\n",
        "  testX, testY = create_dataset(test_data, time_step)\n",
        "\n",
        "  print(trainX.shape), print(trainY.shape)\n",
        "  print(testX.shape), print(testY.shape)\n",
        "\n",
        "  trainX = trainX.reshape(trainX.shape[0],trainX.shape[1] , 1)\n",
        "  testX = testX.reshape(testX.shape[0],testX.shape[1] , 1)\n",
        "\n",
        "  # Stacked LSTM model\n",
        "\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import LSTM\n",
        "  from tensorflow.keras.layers import Dense\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, return_sequences=True, input_shape= (step, 1)))\n",
        "  model.add(LSTM(64, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "  #Train Model\n",
        "  model.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=64,verbose=1)\n",
        "\n",
        "\n",
        "  # Prediction and error calculation\n",
        "  train_predict = model.predict(trainX)\n",
        "  test_predict = model.predict(testX)\n",
        "\n",
        "  print(test_predict.shape)\n",
        "  testY = testY.reshape(test_size-step-1,1)\n",
        "  trainY = trainY.reshape(train_size-step-1,1)\n",
        "\n",
        "  testY = mms.inverse_transform(testY)\n",
        "  trainY = mms.inverse_transform(trainY)\n",
        "\n",
        "  print(testY[0])\n",
        "  print(trainY[0])\n",
        "\n",
        "  train_predict = mms.inverse_transform(train_predict)\n",
        "  test_predict = mms.inverse_transform(test_predict)\n",
        "\n",
        "  print(train_predict[0])\n",
        "  print(test_predict[0])\n",
        "\n",
        "  print(\"Train data error =\",math.sqrt(mean_squared_error(trainY,train_predict)))\n",
        "  print(\"Test data error =\",math.sqrt(mean_squared_error(testY,test_predict)))\n",
        "\n",
        "\n",
        "  plt.style.use(\"fivethirtyeight\")  \n",
        "  plt.figure(figsize=(14,8))\n",
        "  plt.title(price_type.capitalize())\n",
        "  plt.plot(test_predict,label = \"predict\")\n",
        "  plt.plot(testY,label = \"original\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}